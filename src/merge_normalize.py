import pandas as pd
import numpy as np
import re
from datetime import datetime
import os
from typing import Dict, Any, Optional, List
import json


def load_data() -> Optional[Dict[str, pd.DataFrame]]:
    """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    data_sources = {}

    try:
        print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")

        files_to_load = [
            ('seed', 'data/raw/companies_seed.csv'),
            ('enriched', 'data/raw/enriched_companies_improved_20251223_165111.csv'),
            ('jobs_detailed', 'data/raw/jobs_detailed_20251223_1656.csv'),
            ('jobs_simple', 'data/raw/jobs_simplified.csv')
        ]

        for source_name, file_path in files_to_load:
            if os.path.exists(file_path):
                try:
                    df = pd.read_csv(file_path)
                    data_sources[source_name] = df
                    print(f"‚úÖ {source_name}: {len(df)} –∑–∞–ø–∏—Å–µ–π")
                    print(f"   –ö–æ–ª–æ–Ω–∫–∏ ({len(df.columns)}): {', '.join(df.columns[:10])}" +
                          ("..." if len(df.columns) > 10 else ""))
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {file_path}: {e}")
            else:
                print(f"‚ö†Ô∏è  –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")

        if not data_sources:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return None

        return data_sources

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None


def extract_all_company_info(row: pd.Series, source: str) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –í–°–ï–ô –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
    info = {'source': source}

    # 1. –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    name_candidates = ['name', 'company_name', 'employer', 'hh_employer_name']
    for col in name_candidates:
        if col in row and pd.notna(row[col]):
            info['name'] = str(row[col]).strip()
            break

    # 2. –ö–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
    # –°–∞–π—Ç—ã
    site_candidates = ['site', 'site_url', 'website', 'final_url', 'url', 'hh_employer_url', 'support_url', 'kb_url']
    sites = []
    for col in site_candidates:
        if col in row and pd.notna(row[col]):
            site = str(row[col]).strip()
            if site and site not in sites:
                sites.append(site)
    info['sites'] = sites

    # Email - –∏—â–µ–º –≤–æ –≤—Å–µ—Ö –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–∫–∞—Ö
    email_candidates = ['support_email', 'email', 'e-mail', 'contact_email']
    emails = []
    for col in email_candidates:
        if col in row and pd.notna(row[col]):
            email_val = str(row[col]).strip()
            if '@' in email_val and email_val not in emails:
                emails.append(email_val)
    info['emails'] = emails

    # 3. –ë–∏–∑–Ω–µ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    if 'industry' in row and pd.notna(row['industry']):
        info['industry'] = str(row['industry']).strip()

    if 'inn' in row and pd.notna(row['inn']):
        info['inn'] = str(row['inn']).strip()

    # 4. Support –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (—Å–∞–º–∞—è –≤–∞–∂–Ω–∞—è —á–∞—Å—Ç—å!)
    support_info = {}

    # –†–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏
    size_cols = ['support_team_size_min', 'support_team_size', 'team_size']
    for col in size_cols:
        if col in row and pd.notna(row[col]):
            try:
                support_info['team_size'] = int(float(row[col]))
            except:
                support_info['team_size'] = str(row[col]).strip()
            break

    # –ù–∞–ª–∏—á–∏–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏
    evidence_cols = ['support_evidence', 'evidence_type']
    for col in evidence_cols:
        if col in row and pd.notna(row[col]):
            support_info['evidence'] = str(row[col]).strip()
            break

    # URL –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤
    if 'evidence_url' in row and pd.notna(row['evidence_url']):
        support_info['evidence_url'] = str(row['evidence_url']).strip()

    # –ö–∞–Ω–∞–ª—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏
    channels = {}
    if 'has_support_email' in row and pd.notna(row['has_support_email']):
        channels['email'] = bool(row['has_support_email'])
    if 'has_contact_form' in row and pd.notna(row['has_contact_form']):
        channels['contact_form'] = bool(row['has_contact_form'])
    if 'has_online_chat' in row and pd.notna(row['has_online_chat']):
        channels['online_chat'] = bool(row['has_online_chat'])
    if 'has_messengers' in row and pd.notna(row['has_messengers']):
        channels['messengers'] = bool(row['has_messengers'])
    if 'has_support_section' in row and pd.notna(row['has_support_section']):
        channels['support_section'] = bool(row['has_support_section'])
    if 'has_kb_or_faq' in row and pd.notna(row['has_kb_or_faq']):
        channels['kb_faq'] = bool(row['has_kb_or_faq'])
    if 'mentions_24_7' in row and pd.notna(row['mentions_24_7']):
        channels['24_7'] = bool(row['mentions_24_7'])

    if channels:
        support_info['channels'] = channels

    # –í–µ–Ω–¥–æ—Ä —á–∞—Ç–∞
    if 'chat_vendor' in row and pd.notna(row['chat_vendor']):
        support_info['chat_vendor'] = str(row['chat_vendor']).strip()

    # –í–∞–∫–∞–Ω—Å–∏–∏ –ø–æ–¥–¥–µ—Ä–∂–∫–∏
    if 'support_vacancies_found' in row and pd.notna(row['support_vacancies_found']):
        try:
            support_info['support_vacancies'] = int(float(row['support_vacancies_found']))
        except:
            support_info['support_vacancies'] = str(row['support_vacancies_found']).strip()

    # –î–µ—Ç–∞–ª–∏ –≤–∞–∫–∞–Ω—Å–∏–π
    if 'vacancy_details' in row and pd.notna(row['vacancy_details']):
        support_info['vacancy_details'] = str(row['vacancy_details']).strip()

    if 'vacancies_count' in row and pd.notna(row['vacancies_count']):
        try:
            support_info['total_vacancies'] = int(float(row['vacancies_count']))
        except:
            support_info['total_vacancies'] = str(row['vacancies_count']).strip()

    if support_info:
        info['support_info'] = support_info

    # 5. –ê–Ω–∞–ª–∏–∑ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    meta = {}
    if 'parsing_success' in row and pd.notna(row['parsing_success']):
        meta['parsing_success'] = bool(row['parsing_success'])
    if 'parsing_method' in row and pd.notna(row['parsing_method']):
        meta['parsing_method'] = str(row['parsing_method']).strip()
    if 'analysis_success' in row and pd.notna(row['analysis_success']):
        meta['analysis_success'] = bool(row['analysis_success'])
    if 'source' in row and pd.notna(row['source']):
        meta['data_source'] = str(row['source']).strip()
    if 'page_title' in row and pd.notna(row['page_title']):
        meta['page_title'] = str(row['page_title']).strip()

    if meta:
        info['metadata'] = meta

    return info


def normalize_company_name(name: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏"""
    if not name or pd.isna(name):
        return ""

    name = str(name).strip()

    # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    name = re.sub(r'\s+', ' ', name)

    # –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –µ–¥–∏–Ω–æ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª)
    normalized = name.upper()

    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    normalized = re.sub(r'[¬´¬ª"\'()\[\]!?.,;:]', '', normalized)

    return normalized.strip()


def normalize_url(url: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL"""
    if not url or pd.isna(url):
        return ""

    url = str(url).strip().lower()

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –µ—Å–ª–∏ –Ω–µ—Ç
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url

    # –£–¥–∞–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    url = re.sub(r'\?.*$', '', url)

    # –£–¥–∞–ª–µ–Ω–∏–µ —Å–ª–µ—à–µ–π –≤ –∫–æ–Ω—Ü–µ
    url = re.sub(r'/$', '', url)

    return url


def calculate_company_score(company: Dict[str, Any]) -> int:
    """–†–∞—Å—á–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –æ –∫–æ–º–ø–∞–Ω–∏–∏"""
    score = 0

    # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (30 –±–∞–ª–ª–æ–≤)
    if company.get('name'):
        score += 10
    if company.get('inn'):
        score += 10
    if company.get('industry'):
        score += 10

    # –ö–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (30 –±–∞–ª–ª–æ–≤)
    if company.get('primary_site'):
        score += 15
    if company.get('primary_email'):
        score += 15

    # Support –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è (40 –±–∞–ª–ª–æ–≤)
    support_info = company.get('support_info', {})
    if support_info:
        score += 10  # –ó–∞ –Ω–∞–ª–∏—á–∏–µ –ª—é–±–æ–π support –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

        if support_info.get('team_size'):
            score += 10
        if support_info.get('evidence'):
            score += 10
        if support_info.get('channels'):
            channels = support_info['channels']
            # –ó–∞ –∫–∞–∂–¥—ã–π –∫–∞–Ω–∞–ª –ø–æ–¥–¥–µ—Ä–∂–∫–∏
            channel_count = sum(1 for v in channels.values() if v)
            score += min(channel_count * 3, 10)

    return min(score, 100)


def merge_company_info(existing: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
    """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    merged = existing.copy() if existing else {}

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏–º—è –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    if not merged.get('name') and new.get('name'):
        merged['name'] = new['name']

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–∞–π—Ç—ã
    existing_sites = merged.get('sites', [])
    new_sites = new.get('sites', [])
    all_sites = list(set(existing_sites + new_sites))
    if all_sites:
        merged['sites'] = all_sites
        merged['primary_site'] = all_sites[0]  # –ü–µ—Ä–≤—ã–π —Å–∞–π—Ç –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º email
    existing_emails = merged.get('emails', [])
    new_emails = new.get('emails', [])
    all_emails = list(set(existing_emails + new_emails))
    if all_emails:
        merged['emails'] = all_emails
        merged['primary_email'] = all_emails[0]  # –ü–µ—Ä–≤—ã–π email –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π

    # –û–±–Ω–æ–≤–ª—è–µ–º –±–∏–∑–Ω–µ—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    for field in ['industry', 'inn']:
        if field in new and new[field] and not merged.get(field):
            merged[field] = new[field]

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º support –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
    existing_support = merged.get('support_info', {})
    new_support = new.get('support_info', {})

    if existing_support or new_support:
        merged_support = existing_support.copy()

        # –û–±–Ω–æ–≤–ª—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø–æ–ª—è (–±–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ)
        for field in ['team_size', 'support_vacancies', 'total_vacancies']:
            if field in new_support:
                new_val = new_support[field]
                if field in merged_support:
                    try:
                        # –ë–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        if isinstance(new_val, (int, float)) and isinstance(merged_support[field], (int, float)):
                            merged_support[field] = max(merged_support[field], new_val)
                        else:
                            merged_support[field] = new_val
                    except:
                        merged_support[field] = new_val
                else:
                    merged_support[field] = new_val

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–∞–Ω–∞–ª—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏
        if 'channels' in new_support:
            if 'channels' not in merged_support:
                merged_support['channels'] = {}
            for channel, value in new_support['channels'].items():
                if channel not in merged_support['channels'] or not merged_support['channels'][channel]:
                    merged_support['channels'][channel] = value

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è
        for field in ['evidence', 'evidence_url', 'chat_vendor', 'vacancy_details']:
            if field in new_support and new_support[field] and not merged_support.get(field):
                merged_support[field] = new_support[field]

        merged['support_info'] = merged_support

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    existing_meta = merged.get('metadata', {})
    new_meta = new.get('metadata', {})

    if existing_meta or new_meta:
        merged_meta = existing_meta.copy()
        for key, value in new_meta.items():
            if key not in merged_meta:
                merged_meta[key] = value
        merged['metadata'] = merged_meta

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    if 'sources' not in merged:
        merged['sources'] = []

    if new.get('source') and new['source'] not in merged['sources']:
        merged['sources'].append(new['source'])

    # –î–æ–±–∞–≤–ª—è–µ–º timestamp
    merged['last_updated'] = datetime.now().isoformat()

    return merged


def create_master_dataset(data_sources: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    """–°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å—Ç–µ—Ä-–¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    print("\nüîó –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å—Ç–µ—Ä-–¥–∞—Ç–∞—Å–µ—Ç–∞...")

    master_companies = {}  # normalized_name -> company_data

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
    for source_name, df in data_sources.items():
        print(f"   üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ {source_name} ({len(df)} –∑–∞–ø–∏—Å–µ–π)...")

        for idx, row in df.iterrows():
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
            company_info = extract_all_company_info(row, source_name)

            if not company_info.get('name'):
                continue

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏–º—è –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏
            normalized_name = normalize_company_name(company_info['name'])

            if normalized_name in master_companies:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –∑–∞–ø–∏—Å—å—é
                master_companies[normalized_name] = merge_company_info(
                    master_companies[normalized_name],
                    company_info
                )
            else:
                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–ø–∏—Å—å
                company_info['normalized_name'] = normalized_name
                master_companies[normalized_name] = company_info

    print(f"   ‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(master_companies)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π")
    return master_companies


def enhance_and_score_companies(master_companies: Dict[str, Any]) -> List[Dict[str, Any]]:
    """–£–ª—É—á—à–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞—Å—á–µ—Ç –∏—Ç–æ–≥–æ–≤—ã—Ö –æ—Ü–µ–Ω–æ–∫"""
    print("   üéØ –£–ª—É—á—à–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞—Å—á–µ—Ç –æ—Ü–µ–Ω–æ–∫...")

    enhanced_companies = []

    for normalized_name, company in master_companies.items():
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID
        company['company_id'] = f"C{len(enhanced_companies) + 1:04d}"

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ—Ü–µ–Ω–∫–∏
        company['data_quality_score'] = calculate_company_score(company)

        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        support_info = company.get('support_info', {})

        # –ù–∞–ª–∏—á–∏–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏
        company['has_support_team'] = bool(support_info.get('team_size'))
        company['support_team_size'] = support_info.get('team_size', 0)

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏
        channels = support_info.get('channels', {})
        company['support_channels_count'] = sum(1 for v in channels.values() if v)
        company['has_24_7_support'] = channels.get('24_7', False)

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö
        company['support_vacancies'] = support_info.get('support_vacancies', 0)
        company['total_vacancies'] = support_info.get('total_vacancies', 0)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        company['data_sources'] = ', '.join(company.get('sources', []))

        # –°–æ–∑–¥–∞–µ–º —á–∏—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
        description_parts = []
        if company.get('industry'):
            description_parts.append(f"–û—Ç—Ä–∞—Å–ª—å: {company['industry']}")
        if company.get('support_team_size'):
            description_parts.append(f"–†–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏: {company['support_team_size']}")
        if company.get('support_channels_count', 0) > 0:
            description_parts.append(f"–ö–∞–Ω–∞–ª—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏: {company['support_channels_count']}")

        company['description'] = ' | '.join(description_parts) if description_parts else "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"

        enhanced_companies.append(company)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ—Ü–µ–Ω–∫–µ –∫–∞—á–µ—Å—Ç–≤–∞
    enhanced_companies.sort(key=lambda x: x['data_quality_score'], reverse=True)

    print(f"   ‚úÖ –£–ª—É—á—à–µ–Ω–æ {len(enhanced_companies)} –∫–æ–º–ø–∞–Ω–∏–π")
    return enhanced_companies


def save_enhanced_results(companies: List[Dict[str, Any]]):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    if not companies:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return

    os.makedirs('data/processed', exist_ok=True)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    df = pd.DataFrame(companies)

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä—è–¥–æ–∫ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    core_columns = [
        'company_id', 'name', 'normalized_name', 'industry', 'inn',
        'primary_site', 'primary_email', 'data_quality_score'
    ]

    support_columns = [
        'has_support_team', 'support_team_size', 'support_channels_count',
        'has_24_7_support', 'support_vacancies', 'total_vacancies'
    ]

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    all_columns = []

    # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ (–≤—Å–µ–≥–¥–∞ –ø–µ—Ä–≤—ã–µ)
    for col in core_columns:
        if col in df.columns:
            all_columns.append(col)

    # Support –∫–æ–ª–æ–Ω–∫–∏
    for col in support_columns:
        if col in df.columns:
            all_columns.append(col)

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –∞–ª—Ñ–∞–≤–∏—Ç–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    other_columns = sorted([col for col in df.columns if col not in all_columns])
    all_columns.extend(other_columns)

    # –†–µ–æ—Ä–≥–∞–Ω–∏–∑—É–µ–º DataFrame
    df = df[all_columns]

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
    # 1. –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª (CSV)
    main_filename = f'companies_master_dataset_{timestamp}.csv'
    main_path = f'data/processed/{main_filename}'
    df.to_csv(main_path, index=False, encoding='utf-8-sig')

    # 2. –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    simple_cols = [
        'company_id', 'name', 'industry', 'primary_site',
        'data_quality_score', 'support_team_size', 'support_channels_count',
        'has_24_7_support', 'data_sources'
    ]
    simple_df = df[[col for col in simple_cols if col in df.columns]]
    simple_filename = f'companies_analysis_view_{timestamp}.csv'
    simple_path = f'data/processed/{simple_filename}'
    simple_df.to_csv(simple_path, index=False, encoding='utf-8-sig')

    # 3. Excel —Å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º
    excel_filename = f'companies_dashboard_{timestamp}.xlsx'
    excel_path = f'data/processed/{excel_filename}'

    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
        # –õ–∏—Å—Ç —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        df.to_excel(writer, sheet_name='–ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ', index=False)

        # –õ–∏—Å—Ç —Å –∞–Ω–∞–ª–∏–∑–æ–º
        analysis_df = df.nlargest(50, 'data_quality_score')
        analysis_df.to_excel(writer, sheet_name='–¢–æ–ø-50 –∫–æ–º–ø–∞–Ω–∏–π', index=False)

        # –õ–∏—Å—Ç —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        stats_data = {
            '–ú–µ—Ç—Ä–∏–∫–∞': [
                '–í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π',
                '–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞',
                '–ö–æ–º–ø–∞–Ω–∏–∏ —Å –∫–æ–º–∞–Ω–¥–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏',
                '–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏',
                '–ö–æ–º–ø–∞–Ω–∏–∏ —Å 24/7 –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π',
                '–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏'
            ],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [
                len(df),
                f"{df['data_quality_score'].mean():.1f}/100",
                f"{df['has_support_team'].sum()} ({df['has_support_team'].sum() / len(df) * 100:.1f}%)",
                f"{df['support_team_size'].mean():.1f}",
                f"{df['has_24_7_support'].sum()} ({df['has_24_7_support'].sum() / len(df) * 100:.1f}%)",
                f"{df['support_channels_count'].mean():.1f}"
            ]
        }
        stats_df = pd.DataFrame(stats_data)
        stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)

    print(f"\nüíæ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–•–†–ê–ù–ï–ù–´:")
    print(f"   üìä –û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª: {main_path}")
    print(f"   üìà –î–ª—è –∞–Ω–∞–ª–∏–∑–∞: {simple_path}")
    print(f"   üìã Excel –¥–∞—à–±–æ—Ä–¥: {excel_path}")

    return df


def print_detailed_analysis(df: pd.DataFrame):
    """–ü–µ—á–∞—Ç—å –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    print("\n" + "=" * 80)
    print("üìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("=" * 80)

    # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    print(f"\nüìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π: {len(df)}")
    print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π: {df['normalized_name'].nunique()}")

    # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –æ—Ü–µ–Ω–∫–∞–º
    print(f"\nüèÜ –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û –û–¶–ï–ù–ö–ê–ú –ö–ê–ß–ï–°–¢–í–ê:")
    bins = [0, 30, 50, 70, 90, 100]
    labels = ['–û—á–µ–Ω—å –Ω–∏–∑–∫–æ–µ', '–ù–∏–∑–∫–æ–µ', '–°—Ä–µ–¥–Ω–µ–µ', '–í—ã—Å–æ–∫–æ–µ', '–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ']

    df['quality_category'] = pd.cut(df['data_quality_score'], bins=bins, labels=labels, right=False)
    quality_dist = df['quality_category'].value_counts().sort_index()

    for category, count in quality_dist.items():
        percentage = count / len(df) * 100
        print(f"   {category}: {count} –∫–æ–º–ø–∞–Ω–∏–π ({percentage:.1f}%)")

    # –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–¥–µ—Ä–∂–∫–∏
    print(f"\nüõ°Ô∏è  –ê–ù–ê–õ–ò–ó –ü–û–î–î–ï–†–ñ–ö–ò:")
    print(
        f"   –ö–æ–º–ø–∞–Ω–∏–∏ —Å –∫–æ–º–∞–Ω–¥–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏: {df['has_support_team'].sum()} ({df['has_support_team'].sum() / len(df) * 100:.1f}%)")
    print(
        f"   –ö–æ–º–ø–∞–Ω–∏–∏ —Å 24/7 –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π: {df['has_24_7_support'].sum()} ({df['has_24_7_support'].sum() / len(df) * 100:.1f}%)")

    if 'support_team_size' in df.columns:
        avg_team_size = df[df['support_team_size'] > 0]['support_team_size'].mean()
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏: {avg_team_size:.1f} —á–µ–ª–æ–≤–µ–∫")

    if 'support_channels_count' in df.columns:
        avg_channels = df['support_channels_count'].mean()
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏: {avg_channels:.1f}")

    # –¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–π
    print(f"\nüèÖ –¢–û–ü-10 –ö–û–ú–ü–ê–ù–ò–ô –ü–û –ö–ê–ß–ï–°–¢–í–£ –î–ê–ù–ù–´–•:")
    top_10 = df.nlargest(10, 'data_quality_score')

    for idx, row in top_10.iterrows():
        score = row['data_quality_score']
        name = row.get('name', '')[:35]
        industry = row.get('industry', '')[:20]
        team_size = row.get('support_team_size', 0)
        channels = row.get('support_channels_count', 0)

        print(f"   {score:3.0f}/100 | {name:35} | {industry:20} | –ö–æ–º–∞–Ω–¥–∞: {team_size:2d} | –ö–∞–Ω–∞–ª—ã: {channels}")

    # –ê–Ω–∞–ª–∏–∑ –ø–æ –æ—Ç—Ä–∞—Å–ª—è–º
    if 'industry' in df.columns:
        print(f"\nüè≠ –ê–ù–ê–õ–ò–ó –ü–û –û–¢–†–ê–°–õ–Ø–ú:")
        industry_stats = df.groupby('industry').agg({
            'data_quality_score': 'mean',
            'has_support_team': 'sum',
            'support_team_size': 'mean'
        }).round(1)

        industry_stats = industry_stats.sort_values('data_quality_score', ascending=False).head(10)

        for industry, stats in industry_stats.iterrows():
            avg_score = stats['data_quality_score']
            support_count = stats['has_support_team']
            avg_team = stats['support_team_size']

            print(
                f"   {industry[:30]:30} | –û—Ü–µ–Ω–∫–∞: {avg_score:.0f}/100 | –° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π: {support_count} | –°—Ä. –∫–æ–º–∞–Ω–¥–∞: {avg_team:.0f}")

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –£–õ–£–ß–®–ï–ù–ò–Ø:")
    low_quality = df[df['data_quality_score'] < 50]
    if len(low_quality) > 0:
        print(f"   ‚Ä¢ {len(low_quality)} –∫–æ–º–ø–∞–Ω–∏–π –∏–º–µ—é—Ç –æ—Ü–µ–Ω–∫—É –Ω–∏–∂–µ 50 - —Ç—Ä–µ–±—É—é—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö")

    no_support = df[~df['has_support_team']]
    if len(no_support) > 0:
        print(f"   ‚Ä¢ {len(no_support)} –∫–æ–º–ø–∞–Ω–∏–π –Ω–µ –∏–º–µ—é—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–∞–Ω–¥–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏")

    print(f"   ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–æ–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è email –∏ —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 80)
    print("üöÄ –ó–ê–ü–£–°–ö –ü–†–û–§–ï–°–°–ò–û–ù–ê–õ–¨–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò –î–ê–ù–ù–´–• –ö–û–ú–ü–ê–ù–ò–ô")
    print("=" * 80)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    data_sources = load_data()

    if not data_sources:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return

    # –°–æ–∑–¥–∞–Ω–∏–µ –º–∞—Å—Ç–µ—Ä-–¥–∞—Ç–∞—Å–µ—Ç–∞
    master_companies = create_master_dataset(data_sources)

    if not master_companies:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –º–∞—Å—Ç–µ—Ä-–¥–∞—Ç–∞—Å–µ—Ç")
        return

    # –£–ª—É—á—à–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    enhanced_companies = enhance_and_score_companies(master_companies)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    result_df = save_enhanced_results(enhanced_companies)

    # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    print_detailed_analysis(result_df)

    print("\n" + "=" * 80)
    print("‚úÖ –ü–†–û–¶–ï–°–° –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù!")
    print("=" * 80)


if __name__ == "__main__":
    main()