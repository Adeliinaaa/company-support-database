"""
–ú–æ–¥—É–ª—å –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã.
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≥–∏–±–∫–∏–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π, —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–æ–π –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
"""

import pandas as pd
import numpy as np
import os
import json
from datetime import datetime
from typing import List, Dict, Any, Optional, Union
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class CompanyDataExporter:
    """–ö–ª–∞—Å—Å –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π –≤ —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã"""

    def __init__(self, data_path: str = 'data/processed/'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞

        Args:
            data_path: –ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        """
        self.data_path = data_path
        self.latest_file = self._find_latest_file()

    def _find_latest_file(self) -> Optional[str]:
        """–ù–∞–π—Ç–∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ñ–∞–π–ª"""
        try:
            if not os.path.exists(self.data_path):
                return None

            # –ò—â–µ–º —Ñ–∞–π–ª—ã —Å –∫–æ–º–ø–∞–Ω–∏—è–º–∏
            company_files = [f for f in os.listdir(self.data_path)
                             if f.startswith('companies_') and f.endswith('.csv')]

            if not company_files:
                return None

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ (—Å–∞–º—ã–π –Ω–æ–≤—ã–π –ø–µ—Ä–≤—ã–π)
            company_files.sort(reverse=True)

            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º—ã–π –Ω–æ–≤—ã–π –ø–æ–ª–Ω—ã–π —Ñ–∞–π–ª
            for file in company_files:
                if 'master_dataset' in file or 'complete' in file:
                    return os.path.join(self.data_path, file)

            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ master_dataset, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π
            return os.path.join(self.data_path, company_files[0])

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ñ–∞–π–ª–∞: {e}")
            return None

    def load_data(self, file_path: Optional[str] = None) -> Optional[pd.DataFrame]:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É (–µ—Å–ª–∏ None, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–π)

        Returns:
            DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        if file_path is None:
            file_path = self.latest_file

        if file_path is None or not os.path.exists(file_path):
            logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            return None

        try:
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –∏–∑ {file_path}")
            return df
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None

    def export_to_formats(self, df: pd.DataFrame, export_name: str = "export") -> Dict[str, str]:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –≤–æ –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã

        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            export_name: –ë–∞–∑–æ–≤–æ–µ –∏–º—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø—É—Ç—è–º–∏ –∫ —Å–æ–∑–¥–∞–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        export_dir = f'exports/{timestamp}_{export_name}'
        os.makedirs(export_dir, exist_ok=True)

        export_paths = {}

        # 1. CSV —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        csv_path = os.path.join(export_dir, f'{export_name}_full.csv')
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        export_paths['csv_full'] = csv_path

        # 2. Excel —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ª–∏—Å—Ç–∞–º–∏
        excel_path = os.path.join(export_dir, f'{export_name}_dashboard.xlsx')
        self._export_to_excel(df, excel_path)
        export_paths['excel'] = excel_path

        # 3. JSON –¥–ª—è –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
        json_path = os.path.join(export_dir, f'{export_name}_data.json')
        self._export_to_json(df, json_path)
        export_paths['json'] = json_path

        # 4. HTML –æ—Ç—á–µ—Ç
        html_path = os.path.join(export_dir, f'{export_name}_report.html')
        self._export_to_html(df, html_path)
        export_paths['html'] = html_path

        # 5. Markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è
        md_path = os.path.join(export_dir, f'{export_name}_README.md')
        self._export_to_markdown(df, md_path)
        export_paths['markdown'] = md_path

        logger.info(f"–î–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ {export_dir}")
        return export_paths

    def export_filtered(self, df: pd.DataFrame, filters: Dict[str, Any],
                        export_name: str = "filtered") -> Optional[pd.DataFrame]:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

        Args:
            df: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            filters: –°–ª–æ–≤–∞—Ä—å —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
            export_name: –ò–º—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞

        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π DataFrame
        """
        try:
            filtered_df = df.copy()

            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã
            for column, value in filters.items():
                if column in filtered_df.columns:
                    if isinstance(value, (list, tuple)):
                        # –§–∏–ª—å—Ç—Ä –ø–æ —Å–ø–∏—Å–∫—É –∑–Ω–∞—á–µ–Ω–∏–π
                        filtered_df = filtered_df[filtered_df[column].isin(value)]
                    elif isinstance(value, dict):
                        # –°–ª–æ–∂–Ω—ã–π —Ñ–∏–ª—å—Ç—Ä (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–∏–∞–ø–∞–∑–æ–Ω)
                        if 'min' in value and 'max' in value:
                            filtered_df = filtered_df[
                                (filtered_df[column] >= value['min']) &
                                (filtered_df[column] <= value['max'])
                                ]
                    else:
                        # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ
                        filtered_df = filtered_df[filtered_df[column] == value]

            if len(filtered_df) > 0:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                export_dir = f'exports/{timestamp}_{export_name}'
                os.makedirs(export_dir, exist_ok=True)

                export_path = os.path.join(export_dir, f'{export_name}_data.csv')
                filtered_df.to_csv(export_path, index=False, encoding='utf-8-sig')

                logger.info(f"–≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(filtered_df)} –∑–∞–ø–∏—Å–µ–π –≤ {export_path}")
                return filtered_df
            else:
                logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö —Ñ–∏–ª—å—Ç—Ä–∞–º")
                return None

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {e}")
            return None

    def export_by_quality(self, df: pd.DataFrame, min_score: int = 0,
                          max_score: int = 100) -> Dict[str, pd.DataFrame]:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–∞—á–µ—Å—Ç–≤—É

        Args:
            df: –ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            min_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            max_score: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å DataFrames –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∫–∞—á–µ—Å—Ç–≤–∞
        """
        if 'data_quality_score' not in df.columns:
            logger.error("–í –¥–∞–Ω–Ω—ã—Ö –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ data_quality_score")
            return {}

        results = {}

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        categories = [
            ('excellent', 80, 100, '–û—Ç–ª–∏—á–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (80-100)'),
            ('good', 60, 79, '–•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (60-79)'),
            ('average', 40, 59, '–°—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (40-59)'),
            ('poor', 0, 39, '–ù–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (0-39)')
        ]

        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        export_dir = f'exports/{timestamp}_by_quality'
        os.makedirs(export_dir, exist_ok=True)

        for cat_id, min_cat, max_cat, cat_name in categories:
            cat_df = df[
                (df['data_quality_score'] >= min_cat) &
                (df['data_quality_score'] <= max_cat)
                ].copy()

            if len(cat_df) > 0:
                cat_df = cat_df.sort_values('data_quality_score', ascending=False)

                # –≠–∫—Å–ø–æ—Ä—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                export_path = os.path.join(export_dir, f'companies_{cat_id}_{len(cat_df)}.csv')
                cat_df.to_csv(export_path, index=False, encoding='utf-8-sig')

                results[cat_id] = cat_df
                logger.info(f"{cat_name}: {len(cat_df)} –∫–æ–º–ø–∞–Ω–∏–π")

        # –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
        summary_path = os.path.join(export_dir, 'quality_summary.md')
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("# –°–≤–æ–¥–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –¥–∞–Ω–Ω—ã—Ö\n\n")
            for cat_id, min_cat, max_cat, cat_name in categories:
                if cat_id in results:
                    count = len(results[cat_id])
                    percentage = (count / len(df)) * 100
                    f.write(f"## {cat_name}\n")
                    f.write(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–∞–Ω–∏–π: {count} ({percentage:.1f}%)\n")
                    f.write(f"- –î–∏–∞–ø–∞–∑–æ–Ω –æ—Ü–µ–Ω–æ–∫: {min_cat}-{max_cat}\n")

                    if len(results[cat_id]) > 0:
                        avg_score = results[cat_id]['data_quality_score'].mean()
                        f.write(f"- –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {avg_score:.1f}\n")

                        top_3 = results[cat_id].head(3)
                        f.write("\n### –¢–æ–ø-3 –∫–æ–º–ø–∞–Ω–∏–∏:\n")
                        for idx, row in top_3.iterrows():
                            f.write(f"- **{row.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')}**: {row['data_quality_score']}/100\n")

                    f.write("\n")

        return results

    def export_analysis_report(self, df: pd.DataFrame,
                               report_name: str = "analysis_report") -> str:
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ—Ç—á–µ—Ç–∞

        Args:
            df: –î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            report_name: –ò–º—è –æ—Ç—á–µ—Ç–∞

        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É –æ—Ç—á–µ—Ç—É
        """
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        export_dir = f'exports/{timestamp}_{report_name}'
        os.makedirs(export_dir, exist_ok=True)

        report_path = os.path.join(export_dir, f'{report_name}.md')

        with open(report_path, 'w', encoding='utf-8') as f:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç—á–µ—Ç–∞
            f.write(f"# –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç –ø–æ –¥–∞–Ω–Ω—ã–º –∫–æ–º–ø–∞–Ω–∏–π\n\n")
            f.write(f"**–î–∞—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:** {datetime.now().strftime('%d.%m.%Y %H:%M')}\n")
            f.write(f"**–í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π:** {len(df)}\n\n")

            # 1. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            f.write("## 1. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")

            if 'data_quality_score' in df.columns:
                f.write(f"- **–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:** {df['data_quality_score'].mean():.1f}/100\n")
                f.write(f"- **–ú–µ–¥–∏–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞:** {df['data_quality_score'].median():.1f}/100\n")
                f.write(f"- **–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ:** {df['data_quality_score'].std():.1f}\n")
                f.write(f"- **–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞:** {df['data_quality_score'].min():.0f}/100\n")
                f.write(f"- **–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞:** {df['data_quality_score'].max():.0f}/100\n\n")

            # 2. –ó–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ª–µ–π
            f.write("## 2. –ó–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ª–µ–π\n\n")

            fields_to_check = [
                ('name', '–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏'),
                ('industry', '–û—Ç—Ä–∞—Å–ª—å'),
                ('primary_site', '–°–∞–π—Ç'),
                ('primary_email', 'Email'),
                ('support_team_size', '–†–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏'),
                ('data_quality_score', '–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞')
            ]

            for field, description in fields_to_check:
                if field in df.columns:
                    filled = df[field].notna().sum()
                    percentage = (filled / len(df)) * 100
                    f.write(f"- **{description}:** {filled}/{len(df)} ({percentage:.1f}%)\n")

            f.write("\n")

            # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ)
            support_fields = ['has_support_team', 'support_team_size', 'support_channels_count']
            if any(field in df.columns for field in support_fields):
                f.write("## 3. –ê–Ω–∞–ª–∏–∑ –ø–æ–¥–¥–µ—Ä–∂–∫–∏\n\n")

                if 'has_support_team' in df.columns:
                    with_support = df['has_support_team'].sum()
                    percentage = (with_support / len(df)) * 100
                    f.write(f"- **–ö–æ–º–ø–∞–Ω–∏–∏ —Å –∫–æ–º–∞–Ω–¥–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏:** {with_support} ({percentage:.1f}%)\n")

                if 'support_team_size' in df.columns:
                    avg_team = df[df['support_team_size'] > 0]['support_team_size'].mean()
                    if not pd.isna(avg_team):
                        f.write(f"- **–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏:** {avg_team:.1f} —á–µ–ª–æ–≤–µ–∫\n")

                if 'support_channels_count' in df.columns:
                    avg_channels = df['support_channels_count'].mean()
                    f.write(f"- **–°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏:** {avg_channels:.1f}\n")

                f.write("\n")

            # 4. –¢–æ–ø-10 –∫–æ–º–ø–∞–Ω–∏–π
            f.write("## 4. –¢–æ–ø-10 –∫–æ–º–ø–∞–Ω–∏–π –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –¥–∞–Ω–Ω—ã—Ö\n\n")

            if 'data_quality_score' in df.columns and 'name' in df.columns:
                top_10 = df.nlargest(10, 'data_quality_score')

                f.write("| –†–∞–Ω–≥ | –ù–∞–∑–≤–∞–Ω–∏–µ | –û—Ü–µ–Ω–∫–∞ | –û—Ç—Ä–∞—Å–ª—å | –†–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã |\n")
                f.write("|------|----------|--------|---------|----------------|\n")

                for idx, (_, row) in enumerate(top_10.iterrows(), 1):
                    name = row.get('name', '–ë–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è')[:40]
                    score = row['data_quality_score']
                    industry = row.get('industry', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')[:20]
                    team_size = row.get('support_team_size', 0)

                    f.write(f"| {idx} | {name} | {score:.0f}/100 | {industry} | {team_size} |\n")

                f.write("\n")

            # 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            f.write("## 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏\n\n")

            recommendations = []

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–∏–∑–∫–∏—Ö –æ—Ü–µ–Ω–æ–∫
            if 'data_quality_score' in df.columns:
                low_quality = df[df['data_quality_score'] < 50]
                if len(low_quality) > 0:
                    recommendations.append(
                        f"- **{len(low_quality)} –∫–æ–º–ø–∞–Ω–∏–π** –∏–º–µ—é—Ç –æ—Ü–µ–Ω–∫—É –Ω–∏–∂–µ 50. "
                        f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö."
                    )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            if 'primary_email' in df.columns:
                no_email = df[df['primary_email'].isna()].shape[0]
                if no_email > 0:
                    recommendations.append(
                        f"- **{no_email} –∫–æ–º–ø–∞–Ω–∏–π** –Ω–µ –∏–º–µ—é—Ç email. "
                        f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Å—Ç–∏ –ø–∞—Ä—Å–∏–Ω–≥ —Å–∞–π—Ç–æ–≤."
                    )

            if 'primary_site' in df.columns:
                no_site = df[df['primary_site'].isna()].shape[0]
                if no_site > 0:
                    recommendations.append(
                        f"- **{no_site} –∫–æ–º–ø–∞–Ω–∏–π** –Ω–µ –∏–º–µ—é—Ç —Å–∞–π—Ç–∞. "
                        f"–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."
                    )

            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            recommendations.extend([
                "- –†–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –¥–∞–Ω–Ω—ã–µ (–º–∏–Ω–∏–º—É–º —Ä–∞–∑ –≤ –∫–≤–∞—Ä—Ç–∞–ª)",
                "- –í–Ω–µ–¥—Ä–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏–∑–º–µ–Ω–µ–Ω–∏–π –Ω–∞ —Å–∞–π—Ç–∞—Ö –∫–æ–º–ø–∞–Ω–∏–π",
                "- –î–æ–±–∞–≤–∏—Ç—å —Å–±–æ—Ä –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫ (–æ—Ç–∑—ã–≤—ã, —Ä–µ–π—Ç–∏–Ω–≥–∏)",
                "- –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —Å CRM —Å–∏—Å—Ç–µ–º–æ–π –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π"
            ])

            for rec in recommendations:
                f.write(f"{rec}\n")

            # 6. –°–≤–æ–¥–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã (—ç–∫—Å–ø–æ—Ä—Ç –≤ CSV)
            f.write("\n## 6. –°–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ\n\n")
            f.write("–°–≤–æ–¥–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã:\n\n")

            # –≠–∫—Å–ø–æ—Ä—Ç —Å–≤–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            summary_files = []

            # –ü–æ –æ—Ç—Ä–∞—Å–ª—è–º
            if 'industry' in df.columns and 'data_quality_score' in df.columns:
                industry_summary = df.groupby('industry').agg({
                    'data_quality_score': ['count', 'mean', 'min', 'max'],
                    'support_team_size': 'mean'
                }).round(2)

                industry_path = os.path.join(export_dir, 'industry_summary.csv')
                industry_summary.to_csv(industry_path, encoding='utf-8-sig')
                summary_files.append(("–ü–æ –æ—Ç—Ä–∞—Å–ª—è–º", "industry_summary.csv"))

            # –ü–æ –∫–∞—á–µ—Å—Ç–≤—É
            if 'data_quality_score' in df.columns:
                quality_bins = [0, 30, 50, 70, 90, 100]
                quality_labels = ['–û—á–µ–Ω—å –Ω–∏–∑–∫–æ–µ', '–ù–∏–∑–∫–æ–µ', '–°—Ä–µ–¥–Ω–µ–µ', '–í—ã—Å–æ–∫–æ–µ', '–û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ']

                df['quality_category'] = pd.cut(
                    df['data_quality_score'],
                    bins=quality_bins,
                    labels=quality_labels,
                    right=False
                )

                quality_summary = df['quality_category'].value_counts().sort_index()
                quality_path = os.path.join(export_dir, 'quality_summary.csv')
                quality_summary.to_csv(quality_path, encoding='utf-8-sig')
                summary_files.append(("–ü–æ –∫–∞—á–µ—Å—Ç–≤—É", "quality_summary.csv"))

            for title, filename in summary_files:
                f.write(f"- [{title}]({filename})\n")

        logger.info(f"–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {report_path}")
        return report_path

    def _export_to_excel(self, df: pd.DataFrame, excel_path: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ Excel —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ª–∏—Å—Ç–∞–º–∏"""
        try:
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # –õ–∏—Å—Ç 1: –í—Å–µ –¥–∞–Ω–Ω—ã–µ
                df.to_excel(writer, sheet_name='–í—Å–µ –∫–æ–º–ø–∞–Ω–∏–∏', index=False)

                # –õ–∏—Å—Ç 2: –¢–æ–ø –∫–æ–º–ø–∞–Ω–∏–π
                if 'data_quality_score' in df.columns:
                    top_50 = df.nlargest(50, 'data_quality_score')
                    top_50.to_excel(writer, sheet_name='–¢–æ–ø-50 –∫–æ–º–ø–∞–Ω–∏–π', index=False)

                # –õ–∏—Å—Ç 3: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                stats_data = self._generate_statistics(df)
                stats_df = pd.DataFrame(stats_data)
                stats_df.to_excel(writer, sheet_name='–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', index=False)

                # –õ–∏—Å—Ç 4: –ü–æ –æ—Ç—Ä–∞—Å–ª—è–º
                if 'industry' in df.columns:
                    industry_stats = df.groupby('industry').agg({
                        'data_quality_score': 'mean',
                        'support_team_size': 'mean',
                        'name': 'count'
                    }).round(2)
                    industry_stats.to_excel(writer, sheet_name='–ü–æ –æ—Ç—Ä–∞—Å–ª—è–º')

                # –ê–≤—Ç–æ–Ω–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã –∫–æ–ª–æ–Ω–æ–∫
                for sheet_name in writer.sheets:
                    worksheet = writer.sheets[sheet_name]
                    for column in worksheet.columns:
                        max_length = 0
                        column_letter = column[0].column_letter
                        for cell in column:
                            try:
                                if len(str(cell.value)) > max_length:
                                    max_length = len(str(cell.value))
                            except:
                                pass
                        adjusted_width = min(max_length + 2, 50)
                        worksheet.column_dimensions[column_letter].width = adjusted_width

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –≤ Excel: {e}")

    def _export_to_json(self, df: pd.DataFrame, json_path: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç"""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º DataFrame –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            data = df.to_dict(orient='records')

            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            export_data = {
                'metadata': {
                    'export_date': datetime.now().isoformat(),
                    'total_companies': len(df),
                    'columns': list(df.columns)
                },
                'companies': data
            }

            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –≤ JSON: {e}")

    def _export_to_html(self, df: pd.DataFrame, html_path: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ HTML –æ—Ç—á–µ—Ç"""
        try:
            html_content = """
            <!DOCTYPE html>
            <html lang="ru">
            <head>
                <meta charset="UTF-8">
                <meta name="viewport" content="width=device-width, initial-scale=1.0">
                <title>–û—Ç—á–µ—Ç –ø–æ –∫–æ–º–ø–∞–Ω–∏—è–º</title>
                <style>
                    body { font-family: Arial, sans-serif; margin: 40px; }
                    h1 { color: #333; }
                    table { border-collapse: collapse; width: 100%; margin: 20px 0; }
                    th, td { border: 1px solid #ddd; padding: 12px; text-align: left; }
                    th { background-color: #f4f4f4; }
                    tr:nth-child(even) { background-color: #f9f9f9; }
                    .stats { background-color: #e8f4f8; padding: 20px; border-radius: 5px; }
                </style>
            </head>
            <body>
                <h1>üìä –û—Ç—á–µ—Ç –ø–æ –¥–∞–Ω–Ω—ã–º –∫–æ–º–ø–∞–Ω–∏–π</h1>
            """

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            html_content += '<div class="stats">'
            html_content += f'<h3>–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</h3>'
            html_content += f'<p><strong>–í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π:</strong> {len(df)}</p>'

            if 'data_quality_score' in df.columns:
                avg_score = df['data_quality_score'].mean()
                html_content += f'<p><strong>–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞:</strong> {avg_score:.1f}/100</p>'

            html_content += '</div>'

            # –¢–∞–±–ª–∏—Ü–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ (–ø–µ—Ä–≤—ã–µ 50 —Å—Ç—Ä–æ–∫)
            html_content += '<h3>–î–∞–Ω–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–π (–ø–µ—Ä–≤—ã–µ 50)</h3>'
            html_content += df.head(50).to_html(index=False, classes='data-table')

            html_content += """
                <script>
                    // –ü—Ä–æ—Å—Ç–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ç–∞–±–ª–∏—Ü—ã
                    document.addEventListener('DOMContentLoaded', function() {
                        const tables = document.querySelectorAll('table');
                        tables.forEach(table => {
                            const headers = table.querySelectorAll('th');
                            headers.forEach((header, index) => {
                                header.style.cursor = 'pointer';
                                header.addEventListener('click', () => {
                                    sortTable(table, index);
                                });
                            });
                        });
                    });

                    function sortTable(table, column) {
                        const tbody = table.querySelector('tbody');
                        const rows = Array.from(tbody.querySelectorAll('tr'));

                        rows.sort((a, b) => {
                            const aText = a.children[column].textContent;
                            const bText = b.children[column].textContent;

                            // –ü—ã—Ç–∞–µ–º—Å—è —Å—Ä–∞–≤–Ω–∏—Ç—å –∫–∞–∫ —á–∏—Å–ª–∞
                            const aNum = parseFloat(aText.replace(',', '.'));
                            const bNum = parseFloat(bText.replace(',', '.'));

                            if (!isNaN(aNum) && !isNaN(bNum)) {
                                return aNum - bNum;
                            }

                            // –ò–Ω–∞—á–µ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏
                            return aText.localeCompare(bText);
                        });

                        // –û—á–∏—â–∞–µ–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                        rows.forEach(row => tbody.appendChild(row));
                    }
                </script>
            </body>
            </html>
            """

            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –≤ HTML: {e}")

    def _export_to_markdown(self, df: pd.DataFrame, md_path: str):
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ Markdown –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é"""
        try:
            with open(md_path, 'w', encoding='utf-8') as f:
                f.write("# –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ –¥–∞–Ω–Ω—ã–º –∫–æ–º–ø–∞–Ω–∏–π\n\n")
                f.write(f"*–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {datetime.now().strftime('%d.%m.%Y %H:%M')}*\n\n")

                f.write("## –û–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n\n")
                f.write("–î–∞–Ω–Ω—ã–π —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–ø–∞–Ω–∏—è—Ö —Å –æ—Ü–µ–Ω–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö.\n\n")

                f.write("## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö\n\n")
                f.write("| –ö–æ–ª–æ–Ω–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ | –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö | –ü—Ä–∏–º–µ—Ä |\n")
                f.write("|---------|----------|------------|--------|\n")

                # –û–ø–∏—Å–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
                column_descriptions = {
                    'company_id': '–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–æ–º–ø–∞–Ω–∏–∏',
                    'name': '–ù–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏',
                    'industry': '–û—Ç—Ä–∞—Å–ª—å –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏',
                    'primary_site': '–û—Å–Ω–æ–≤–Ω–æ–π —Å–∞–π—Ç –∫–æ–º–ø–∞–Ω–∏–∏',
                    'primary_email': '–û—Å–Ω–æ–≤–Ω–æ–π email –¥–ª—è —Å–≤—è–∑–∏',
                    'data_quality_score': '–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö (0-100)',
                    'support_team_size': '–†–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏',
                    'support_channels_count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–Ω–∞–ª–æ–≤ –ø–æ–¥–¥–µ—Ä–∂–∫–∏',
                    'has_24_7_support': '–ù–∞–ª–∏—á–∏–µ –∫—Ä—É–≥–ª–æ—Å—É—Ç–æ—á–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏'
                }

                for column in df.columns:
                    description = column_descriptions.get(column, '–ù–µ –æ–ø–∏—Å–∞–Ω–æ')
                    dtype = str(df[column].dtype)

                    # –ü—Ä–∏–º–µ—Ä –∑–Ω–∞—á–µ–Ω–∏—è (–ø–µ—Ä–≤–æ–µ –Ω–µ–ø—É—Å—Ç–æ–µ)
                    example = df[column].dropna().iloc[0] if not df[column].isna().all() else '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö'
                    if isinstance(example, str) and len(example) > 30:
                        example = example[:30] + '...'

                    f.write(f"| {column} | {description} | {dtype} | {example} |\n")

                f.write("\n## –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ\n\n")
                f.write("–î–∞–Ω–Ω—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–ª—è:\n")
                f.write("- –ê–Ω–∞–ª–∏–∑–∞ —Ä—ã–Ω–∫–∞\n")
                f.write("- –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∫–ª–∏–µ–Ω—Ç–æ–≤\n")
                f.write("- –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –æ—Ç—Ä–∞—Å–ª–µ–≤—ã—Ö —Ç–µ–Ω–¥–µ–Ω—Ü–∏–π\n")
                f.write("- –û—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –∫–æ–º–ø–∞–Ω–∏–π\n")

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ –≤ Markdown: {e}")

    def _generate_statistics(self, df: pd.DataFrame) -> Dict[str, List]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ—Ç—á–µ—Ç–∞"""
        stats = {
            '–ú–µ—Ç—Ä–∏–∫–∞': [],
            '–ó–Ω–∞—á–µ–Ω–∏–µ': [],
            '–û–ø–∏—Å–∞–Ω–∏–µ': []
        }

        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        stats['–ú–µ—Ç—Ä–∏–∫–∞'].append('–í—Å–µ–≥–æ –∫–æ–º–ø–∞–Ω–∏–π')
        stats['–ó–Ω–∞—á–µ–Ω–∏–µ'].append(len(df))
        stats['–û–ø–∏—Å–∞–Ω–∏–µ'].append('–û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–∞–Ω–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ')

        # –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        if 'data_quality_score' in df.columns:
            stats['–ú–µ—Ç—Ä–∏–∫–∞'].append('–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞')
            stats['–ó–Ω–∞—á–µ–Ω–∏–µ'].append(f"{df['data_quality_score'].mean():.1f}/100")
            stats['–û–ø–∏—Å–∞–Ω–∏–µ'].append('–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ –≤—Å–µ–º –∫–æ–º–ø–∞–Ω–∏—è–º')

            stats['–ú–µ—Ç—Ä–∏–∫–∞'].append('–ö–æ–º–ø–∞–Ω–∏–π —Å –æ—Ü–µ–Ω–∫–æ–π > 70')
            stats['–ó–Ω–∞—á–µ–Ω–∏–µ'].append(len(df[df['data_quality_score'] > 70]))
            stats['–û–ø–∏—Å–∞–Ω–∏–µ'].append('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–ø–∞–Ω–∏–π —Å –≤—ã—Å–æ–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö')

        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞
        if 'has_support_team' in df.columns:
            stats['–ú–µ—Ç—Ä–∏–∫–∞'].append('–ö–æ–º–ø–∞–Ω–∏–∏ —Å –∫–æ–º–∞–Ω–¥–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏')
            stats['–ó–Ω–∞—á–µ–Ω–∏–µ'].append(
                f"{df['has_support_team'].sum()} ({df['has_support_team'].sum() / len(df) * 100:.1f}%)")
            stats['–û–ø–∏—Å–∞–Ω–∏–µ'].append('–î–æ–ª—è –∫–æ–º–ø–∞–Ω–∏–π, –∏–º–µ—é—â–∏—Ö –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–º–∞–Ω–¥–µ –ø–æ–¥–¥–µ—Ä–∂–∫–∏')

        if 'support_team_size' in df.columns:
            avg_team = df[df['support_team_size'] > 0]['support_team_size'].mean()
            if not pd.isna(avg_team):
                stats['–ú–µ—Ç—Ä–∏–∫–∞'].append('–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏')
                stats['–ó–Ω–∞—á–µ–Ω–∏–µ'].append(f"{avg_team:.1f} —á–µ–ª–æ–≤–µ–∫")
                stats['–û–ø–∏—Å–∞–Ω–∏–µ'].append('–°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–º–∞–Ω–¥—ã –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å—Ä–µ–¥–∏ –∫–æ–º–ø–∞–Ω–∏–π, –≥–¥–µ –æ–Ω —É–∫–∞–∑–∞–Ω')

        return stats


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print("=" * 60)
    print("üöÄ –ó–ê–ü–£–°–ö –≠–ö–°–ü–û–†–¢–ê –î–ê–ù–ù–´–• –ö–û–ú–ü–ê–ù–ò–ô")
    print("=" * 60)

    # –°–æ–∑–¥–∞–µ–º —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä
    exporter = CompanyDataExporter()

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    df = exporter.load_data()

    if df is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
        return

    print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∫–æ–º–ø–∞–Ω–∏–π")
    print(f"üìã –ö–æ–ª–æ–Ω–∫–∏: {', '.join(df.columns[:10])}" +
          ("..." if len(df.columns) > 10 else ""))

    # –ú–µ–Ω—é —ç–∫—Å–ø–æ—Ä—Ç–∞
    print("\nüìÅ –í–´–ë–ï–†–ò–¢–ï –¢–ò–ü –≠–ö–°–ü–û–†–¢–ê:")
    print("1. üì§ –≠–∫—Å–ø–æ—Ä—Ç –≤–æ –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã")
    print("2. üéØ –≠–∫—Å–ø–æ—Ä—Ç –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –¥–∞–Ω–Ω—ã—Ö")
    print("3. üîç –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç")
    print("4. ‚öôÔ∏è  –§–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç")
    print("5. üìä –í—Å–µ –æ–ø—Ü–∏–∏")
    print("0. ‚ùå –í—ã—Ö–æ–¥")

    try:
        choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä: ").strip()

        if choice == '1':
            # –≠–∫—Å–ø–æ—Ä—Ç –≤–æ –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã
            export_name = input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'companies'): ").strip()
            if not export_name:
                export_name = 'companies'

            paths = exporter.export_to_formats(df, export_name)
            print(f"\n‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ {len(paths)} —Ñ–æ—Ä–º–∞—Ç–æ–≤:")
            for format_name, path in paths.items():
                print(f"   üìÑ {format_name}: {path}")

        elif choice == '2':
            # –≠–∫—Å–ø–æ—Ä—Ç –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
            min_score = input("–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (0-100, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0): ").strip()
            max_score = input("–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (0-100, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 100): ").strip()

            min_score = int(min_score) if min_score else 0
            max_score = int(max_score) if max_score else 100

            results = exporter.export_by_quality(df, min_score, max_score)
            print(f"\n‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(results)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∫–∞—á–µ—Å—Ç–≤–∞")

        elif choice == '3':
            # –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç
            report_name = input("–í–≤–µ–¥–∏—Ç–µ –∏–º—è –æ—Ç—á–µ—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'analysis'): ").strip()
            if not report_name:
                report_name = 'analysis'

            report_path = exporter.export_analysis_report(df, report_name)
            print(f"\n‚úÖ –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: {report_path}")

        elif choice == '4':
            # –§–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç
            print("\n‚öôÔ∏è  –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∏–ª—å—Ç—Ä–æ–≤:")
            print("–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:")
            for i, col in enumerate(df.columns[:15], 1):
                print(f"  {i:2d}. {col}")

            if len(df.columns) > 15:
                print(f"  ... –∏ –µ—â–µ {len(df.columns) - 15} –∫–æ–ª–æ–Ω–æ–∫")

            filter_col = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: ").strip()

            if filter_col in df.columns:
                print(f"\n–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ '{filter_col}':")
                unique_vals = df[filter_col].dropna().unique()
                for val in unique_vals[:10]:
                    print(f"  - {val}")

                if len(unique_vals) > 10:
                    print(f"  ... –∏ –µ—â–µ {len(unique_vals) - 10} –∑–Ω–∞—á–µ–Ω–∏–π")

                filter_val = input(f"\n–í–≤–µ–¥–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ '{filter_col}': ").strip()

                try:
                    # –ü—Ä–æ–±—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —á–∏—Å–ª–æ –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
                    if df[filter_col].dtype in [np.int64, np.float64]:
                        filter_val = float(filter_val)
                except:
                    pass

                filtered = exporter.export_filtered(
                    df,
                    {filter_col: filter_val},
                    f"filtered_by_{filter_col}"
                )

                if filtered is not None:
                    print(f"\n‚úÖ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ {len(filtered)} –∑–∞–ø–∏—Å–µ–π")

        elif choice == '5':
            # –í—Å–µ –æ–ø—Ü–∏–∏
            print("\nüöÄ –ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —ç–∫—Å–ø–æ—Ä—Ç–∞...")

            # 1. –í—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã
            paths = exporter.export_to_formats(df, 'complete_export')
            print(f"‚úÖ –í—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã: {len(paths)} —Ñ–∞–π–ª–æ–≤")

            # 2. –ü–æ –∫–∞—á–µ—Å—Ç–≤—É
            results = exporter.export_by_quality(df)
            print(f"‚úÖ –ü–æ –∫–∞—á–µ—Å—Ç–≤—É: {len(results)} –∫–∞—Ç–µ–≥–æ—Ä–∏–π")

            # 3. –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç
            report_path = exporter.export_analysis_report(df, 'full_analysis')
            print(f"‚úÖ –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –æ—Ç—á–µ—Ç: {report_path}")

            print("\nüìÅ –í—Å–µ —ç–∫—Å–ø–æ—Ä—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ 'exports/'")

        elif choice == '0':
            print("üëã –í—ã—Ö–æ–¥...")
            return

        else:
            print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")

        print("\n" + "=" * 60)
        print("‚úÖ –≠–ö–°–ü–û–†–¢ –ó–ê–í–ï–†–®–ï–ù!")
        print("=" * 60)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()